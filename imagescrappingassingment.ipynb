{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1660922f-f131-4928-841d-83b414a874a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Write a python program to extract the video URL of the first five videos.\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_video_urls(channel_url, num_videos=5):\n",
    "    \n",
    "    response = requests.get(channel_url)\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    video_links = soup.find_all('a', class_='yt-simple-endpoint style-scope ytd-grid-video-renderer')\n",
    "    \n",
    "    video_urls = []\n",
    "    for link in video_links[:num_videos]:\n",
    "        video_urls.append('https://www.youtube.com/@PW-Foundation/videos' + link['href'])\n",
    "    \n",
    "    return video_urls\n",
    "\n",
    "\n",
    "channel_url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "\n",
    "first_five_videos = get_video_urls(channel_url, num_videos=5)\n",
    "print(first_five_videos)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f0c4112-b85f-4926-91af-f6465ce4c5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Write a python program to extract the URL of the video thumbnails of the first five videos.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_thumbnail_urls(channel_url, num_videos=5):\n",
    "    \n",
    "    response = requests.get(channel_url)\n",
    "    \n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    \n",
    "    thumbnail_elements = soup.find_all('img', class_='style-scope yt-img-shadow')\n",
    "    \n",
    "    \n",
    "    thumbnail_urls = []\n",
    "    for element in thumbnail_elements[:num_videos]:\n",
    "        thumbnail_urls.append(element['src'])\n",
    "    \n",
    "    return thumbnail_urls\n",
    "\n",
    "\n",
    "channel_url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "\n",
    "first_five_thumbnail_urls = get_thumbnail_urls(channel_url, num_videos=5)\n",
    "print(first_five_thumbnail_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a9e1e-91c3-4eff-ae7c-9aeca46d14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python program to extract the title of the first five videos.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_video_titles(channel_url, num_videos=5):\n",
    "\n",
    "    response = requests.get(channel_url)\n",
    "    \n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    \n",
    "    title_elements = soup.find_all('a', class_='yt-simple-endpoint style-scope ytd-grid-video-renderer')\n",
    "    \n",
    "    \n",
    "    video_titles = []\n",
    "    for element in title_elements[:num_videos]:\n",
    "        video_titles.append(element.get_text())\n",
    "    \n",
    "    return video_titles\n",
    "\n",
    "\n",
    "channel_url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "\n",
    "first_five_video_titles = get_video_titles(channel_url, num_videos=5)\n",
    "print(first_five_video_titles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb03591-8cf9-4865-b291-1bbb8a21c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python program to extract the number of views of the first five videos.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_video_views(channel_url, num_videos=5):\n",
    "    \n",
    "    response = requests.get(channel_url)\n",
    "    \n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    view_elements = soup.find_all('span', class_='style-scope ytd-grid-video-renderer')\n",
    "    \n",
    "    \n",
    "    video_views = []\n",
    "    for element in view_elements[:num_videos]:\n",
    "        view_text = element.get_text().strip().replace(' views', '').replace(',', '')\n",
    "        video_views.append(int(view_text))\n",
    "    \n",
    "    return video_views\n",
    "\n",
    "\n",
    "channel_url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "\n",
    "first_five_video_views = get_video_views(channel_url, num_videos=5)\n",
    "print(first_five_video_views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb9390-41b1-40ac-a816-911d2c12f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python program to extract the time of posting of video for the first five videos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

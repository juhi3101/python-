{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b892a-5fd3-474b-be81-ab148ada0d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "'''\n",
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in\n",
    "an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various\n",
    "applications.\n",
    "Web scraping is widely used for various purposes due to its practical applications and benefits, some of which include:\n",
    "\n",
    "Data Collection: Web scraping allows users to gather large amounts of data from websites quickly. This data can be used for\n",
    "market research, competitive analysis, sentiment analysis, price monitoring, and more.\n",
    "\n",
    "Content Aggregation: Web scraping enables the aggregation of content from various sources, \n",
    "creating comprehensive databases or news portals.\n",
    "\n",
    "Price Comparison: Online retailers can use web scraping to monitor competitors' prices and adjust their own pricing \n",
    "strategies to remain competitive.\n",
    "\n",
    "Sentiment Analysis\n",
    "If companies want to understand the general sentiment for their products among their consumers,\n",
    "then Sentiment Analysis is a must. Companies can use web scraping to collect data from social media websites \n",
    "such as Facebook and Twitter as to what the general sentiment about their products is.\n",
    "This will help them in creating products that people desire and moving ahead of their competition.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd3a45-f18f-42f2-aea1-8a036a910720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the different methods used for Web Scraping?\n",
    "'''\n",
    "Web scraping can be performed using various methods and technologies,\n",
    "depending on the complexity of the task and the tools available,\n",
    "\n",
    "Manual Copy-Pasting: The simplest form of web scraping involves manually copying and pasting data from a web page into a local \n",
    "document.While this method is straightforward, it is highly time-consuming and not practical for scraping large amounts of data\n",
    "\n",
    "Parsing Libraries (e.g., BeautifulSoup, lxml): These libraries help parse HTML and XML documents, making it easier to extract\n",
    "specific elements, attributes, or text from the page. BeautifulSoup is particularly \n",
    "popular in the Python community for its ease of use.\n",
    "\n",
    "Web Scraping Frameworks (e.g., Scrapy): Scrapy is an open-source web scraping framework for Python. It provides a more\n",
    "structure and efficient way to navigate websites, follow links, and extract data from multiple pages at scale.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea2eca0-b5f8-4a3f-8c78-37ab640a4829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Beautiful Soup? Why is it used?\n",
    "'''\n",
    "Beautiful Soup is a popular Python library ,provides tools for parsing HTML and XML documents, \n",
    "allowing developers to extract data from web pages in a structured and easy-to-use manner.\n",
    "some reason why it is used:\n",
    "\n",
    "HTML Parsing: Beautiful Soup can parse raw HTML documents and create a parse tree, \n",
    "which represents the HTML structure in a way that makes it easy to navigate and search for specific elements or data.\n",
    "\n",
    "Simple and Intuitive API: Beautiful Soup offers an intuitive API that makes it easy for developers to work with HTML documents.\n",
    "The library provides methods and functions to access elements, attributes, and text content with straightforward Python syntax.\n",
    "\n",
    "Compatibility: Beautiful Soup works well with various Python parsers, including the built-in html.parser, as well as external \n",
    "libraries like lxml and html5lib. This flexibility allows developers to choose the parsing engine that best suits their needs.\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfcab86-4111-449a-988e-984726b67365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is flask used in this Web Scraping project?\n",
    "'''\n",
    "Flask is a lightweight framework to build websites. Weâ€™ll use this to parse our collected data and display \n",
    "it as HTML in a new HTML file.The requests module allows us to send http requests to the website we want to scrape.\n",
    "from flask import Flask, render_template \n",
    "The first line imports the Flask class and the render_template method from the flask library\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a21f6e6-8cee-422e-8627-82aade6a4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "'''\n",
    "aws services used in this project is :\n",
    "code pipelining whic is used to connect our git hub to aws server\n",
    "ans \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
